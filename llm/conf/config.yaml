defaults:
  - _self_

OPENAI_API_KEY: ${oc.env:OPENAI_API_KEY, ""}
LOG_DIR: "logs"

data:
  dir: data
  raw_dir: ${data.dir}/raw
  interim_dir: ${data.dir}/interim
  processed_dir: ${data.dir}/processed
  simulated_dir: ${data.dir}/simulated
  results_dir: ${data.dir}/results

figures:
  dir: figures

chromadb:
  collection_name: ctrials
  persist_dir: ${data.raw_dir}/collections

civic:
  raw_file: ${data.raw_dir}/01-Dec-2023-VariantSummaries.tsv
  processed_file: ${data.processed_dir}/civic_processed.csv
  variant_syn_file: ${data.processed_dir}/variants_synonyms.csv
  gene_syn_file: ${data.processed_dir}/gene_synonyms.csv

aacr:
  clinical_sample: ${data.raw_dir}/aacr_genie/data_clinical_sample.txt
  data_mutations: ${data.raw_dir}/aacr_genie/data_mutations_extended.txt
  data_cna: ${data.raw_dir}/aacr_genie/data_CNA.txt
  data_sv: ${data.raw_dir}/aacr_genie/data_sv.txt

split_params:
  random_state: 42
  train_percent: 70

DPO_FT:
  open_source_model: NousResearch/Hermes-2-Pro-Mistral-7B
  fine_tuned_model: nalkhou/Hermes-FT
  fine_tuning_train: ${data.processed_dir}/negative.jsonl
  fine_tuning_test: ${data.processed_dir}/ft_test.jsonl
  beta: 0.1
  learning_rate: 5e-5
  max_steps: 200
  warmup_steps: 100
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 4
  logging_steps: 1
  max_length: 4800

LoRA:
  r: 2
  lora_alpha: 4
  lora_dropout: 0.05
  target_modules: ['k_proj', 'gate_proj', 'v_proj', 'up_proj', 'q_proj', 'o_proj', 'down_proj'] 

DPO_EVAL:
  open_source_model: nalkhou/Hermes-FT
  open_source_eval_file: Fine_tune_a_Mistral_7b_model_with_DPO_zero-shot_zero-shot_loong_r_2_alpha_4.json # Changes depending on what we are evaluating!
  fine_tuning_test: ${data.processed_dir}/ft_test.jsonl


GPT_EVAL:
  n_shot: 0
  model: gpt-3.5-turbo
  OUTPUT_PROMPTS:
    zero_shot: 0shot
    one_shot: 1shot
    two_shot: 2shot
    prompt_chain: 2CoP
  
PROMPT_FILES:
  gpt_zero_shot: prompts/zero-shot.json
  gpt_one_shot: prompts/one-shot.json
  gpt_two_shot: prompts/two-shot.json
  gpt_chain_one: prompts/chain_1.json
  gpt_chain_two: prompts/chain_2.json


